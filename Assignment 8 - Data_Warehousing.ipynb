{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XddWFhPzZHKr"
      },
      "outputs": [],
      "source": [
        "Data Warehousing Fundamentals\n",
        "1.\n",
        "CREATE TABLE products (\n",
        "  product_id INT PRIMARY KEY,\n",
        "  product_name VARCHAR(100),\n",
        "  category VARCHAR(50),\n",
        "  brand VARCHAR(50),\n",
        "  price DECIMAL(10, 2)\n",
        ");\n",
        "CREATE TABLE customers (\n",
        "  customer_id INT PRIMARY KEY,\n",
        "  customer_name VARCHAR(100),\n",
        "  address VARCHAR(200),\n",
        "  city VARCHAR(50),\n",
        "  state VARCHAR(50),\n",
        "  country VARCHAR(50)\n",
        ");\n",
        "CREATE TABLE time (\n",
        "  date_id INT PRIMARY KEY,\n",
        "  date DATE,\n",
        "  day INT,\n",
        "  month INT,\n",
        "  year INT\n",
        ");\n",
        "CREATE TABLE sales (\n",
        "  sale_id INT PRIMARY KEY,\n",
        "  product_id INT,\n",
        "  customer_id INT,\n",
        "  date_id INT,\n",
        "  quantity INT,\n",
        "  amount DECIMAL(10, 2),\n",
        "  FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
        "  FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
        "  FOREIGN KEY (date_id) REFERENCES time(date_id)\n",
        ");\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2.\n",
        "CREATE TABLE sales (\n",
        "  sale_id INT PRIMARY KEY,\n",
        "  product_id INT,\n",
        "  customer_id INT,\n",
        "  date_id INT,\n",
        "  quantity INT,\n",
        "  amount DECIMAL(10, 2),\n",
        "  FOREIGN KEY (product_id) REFERENCES products(product_id),\n",
        "  FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
        "  FOREIGN KEY (date_id) REFERENCES time(date_id)\n",
        ");\n"
      ],
      "metadata": {
        "id": "f0b3aUTRZonm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3.\n",
        "SELECT p.product_name, SUM(s.amount) AS total_sales_amount\n",
        "FROM sales s\n",
        "JOIN products p ON s.product_id = p.product_id\n",
        "GROUP BY p.product_name;\n",
        "\n",
        "SELECT c.customer_name, SUM(s.amount) AS total_sales_amount\n",
        "FROM sales s\n",
        "JOIN customers c ON s.customer_id = c.customer_id\n",
        "GROUP BY c.customer_name;\n",
        "\n",
        "SELECT t.month, SUM(s.amount) AS total_sales_amount\n",
        "FROM sales s\n",
        "JOIN time t ON s.date_id = t.date_id\n",
        "GROUP BY t.month;\n",
        "\n",
        "SELECT p.category, SUM(s.amount) AS total_sales_amount\n",
        "FROM sales s\n",
        "JOIN products p ON s.product_id = p.product_id\n",
        "GROUP BY p.category;\n",
        "SELECT p.product_name, SUM(s.amount) AS total_sales_amount\n",
        "FROM sales s\n",
        "JOIN products p ON s.product_id = p.product_id\n",
        "JOIN time t ON s.date_id = t.date_id\n",
        "WHERE p.product_name = 'Product X' AND t.date BETWEEN '2023-01-01' AND '2023-12-31'\n",
        "GROUP BY p.product_name;\n"
      ],
      "metadata": {
        "id": "n__1ntdEZ0Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ETL and Data Integration\n",
        "1.\n",
        "import csv\n",
        "\n",
        "def extract_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    return data\n",
        "def transform_data(data):\n",
        "    transformed_data = []\n",
        "    for row in data:\n",
        "        # Apply business rules or calculations\n",
        "        transformed_row = {\n",
        "            'column1': row['column1'],\n",
        "            'column2': row['column2'],\n",
        "            'new_column': int(row['column3']) * 2,\n",
        "        }\n",
        "        transformed_data.append(transformed_row)\n",
        "    return transformed_data\n",
        "import psycopg2\n",
        "\n",
        "def load_data(data):\n",
        "    connection = psycopg2.connect(\n",
        "        host='your_host',\n",
        "        port='your_port',\n",
        "        user='your_user',\n",
        "        password='your_password',\n",
        "        database='your_database'\n",
        "    )\n",
        "    cursor = connection.cursor()\n",
        "    for row in data:\n",
        "        # Load data into the data warehouse table\n",
        "        cursor.execute(\"INSERT INTO your_table (column1, column2, new_column) VALUES (%s, %s, %s)\",\n",
        "                       (row['column1'], row['column2'], row['new_column']))\n",
        "    connection.commit()\n",
        "    cursor.close()\n",
        "    connection.close()\n",
        "file_path = 'path_to_your_csv_file.csv'\n",
        "extracted_data = extract_data(file_path)\n",
        "transformed_data = transform_data(extracted_data)\n",
        "load_data(transformed_data)\n"
      ],
      "metadata": {
        "id": "81nHcshVaDKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2.\n",
        "import csv\n",
        "import psycopg2\n",
        "\n",
        "# Extract data from CSV files\n",
        "def extract_data(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    return data\n",
        "\n",
        "# Transform data by applying business rules\n",
        "def transform_data(data):\n",
        "    transformed_data = []\n",
        "    for row in data:\n",
        "        transformed_row = {\n",
        "            'column1': row['column1'],\n",
        "            'column2': row['column2'],\n",
        "            'new_column': int(row['column3']) * 2,\n",
        "        }\n",
        "        transformed_data.append(transformed_row)\n",
        "    return transformed_data\n",
        "\n",
        "# Load data into the PostgreSQL database\n",
        "def load_data(data):\n",
        "    connection = psycopg2.connect(\n",
        "        host='your_host',\n",
        "        port='your_port',\n",
        "        user='your_user',\n",
        "        password='your_password',\n",
        "        database='your_database'\n",
        "    )\n",
        "    cursor = connection.cursor()\n",
        "    for row in data:\n",
        "        cursor.execute(\"INSERT INTO your_table (column1, column2, new_column) VALUES (%s, %s, %s)\",\n",
        "                       (row['column1'], row['column2'], row['new_column']))\n",
        "    connection.commit()\n",
        "    cursor.close()\n",
        "    connection.close()\n",
        "\n",
        "# Perform the ETL process\n",
        "file_path = 'path_to_your_csv_file.csv'\n",
        "extracted_data = extract_data(file_path)\n",
        "transformed_data = transform_data(extracted_data)\n",
        "load_data(transformed_data)\n"
      ],
      "metadata": {
        "id": "ZvWiqOT5aU_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dimensional Modeling and Schemas\n",
        "1.\n",
        "CREATE TABLE student_enrollments (\n",
        "  enrollment_id SERIAL PRIMARY KEY,\n",
        "  student_id INT REFERENCES students(student_id),\n",
        "  course_id INT REFERENCES courses(course_id),\n",
        "  time_id INT REFERENCES time(time_id),\n",
        "  enrollment_date DATE,\n",
        "  enrollment_status VARCHAR(50),\n",
        "  grade FLOAT\n",
        ");\n",
        "CREATE TABLE students (\n",
        "  student_id SERIAL PRIMARY KEY,\n",
        "  student_name VARCHAR(100),\n",
        "  date_of_birth DATE,\n",
        "  gender VARCHAR(10),\n",
        "  major VARCHAR(50)\n",
        ");\n",
        "\n",
        "CREATE TABLE courses (\n",
        "  course_id SERIAL PRIMARY KEY,\n",
        "  course_name VARCHAR(100),\n",
        "  department VARCHAR(50),\n",
        "  credit_hours INT\n",
        ");\n",
        "\n",
        "CREATE TABLE time (\n",
        "  time_id SERIAL PRIMARY KEY,\n",
        "  date DATE,\n",
        "  day_of_week VARCHAR(20),\n",
        "  semester VARCHAR(20),\n",
        "  year INT\n",
        ");\n"
      ],
      "metadata": {
        "id": "wyTbcNE5ahnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2)\n",
        "SELECT s.student_name, c.course_name, se.enrollment_date\n",
        "FROM student_enrollments se\n",
        "JOIN students s ON se.student_id = s.student_id\n",
        "JOIN courses c ON se.course_id = c.course_id;\n",
        "SELECT c.course_name, COUNT(*) AS total_students\n",
        "FROM student_enrollments se\n",
        "JOIN courses c ON se.course_id = c.course_id\n",
        "GROUP BY c.course_name;\n",
        "SELECT c.course_name, AVG(se.grade) AS average_grade\n",
        "FROM student_enrollments se\n",
        "JOIN courses c ON se.course_id = c.course_id\n",
        "JOIN time t ON se.time_id = t.time_id\n",
        "WHERE t.semester = 'Fall' AND t.year = 2022\n",
        "GROUP BY c.course_name;\n",
        "SELECT c.course_name, s.gender, COUNT(*) AS total_students\n",
        "FROM student_enrollments se\n",
        "JOIN students s ON se.student_id = s.student_id\n",
        "JOIN courses c ON se.course_id = c.course_id\n",
        "GROUP BY c.course_name, s.gender;\n",
        "SELECT t.day_of_week, COUNT(*) AS enrollment_count\n",
        "FROM student_enrollments se\n",
        "JOIN time t ON se.time_id = t.time_id\n",
        "GROUP BY t.day_of_week;\n"
      ],
      "metadata": {
        "id": "GmqBXgrGd47L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " Performance Optimization and Querying\n",
        " 1.\n",
        " import psycopg2\n",
        "\n",
        "# Assuming you have a list of data to be inserted\n",
        "data = [(1, 'John'), (2, 'Jane'), (3, 'Mark')]\n",
        "\n",
        "# Establish a connection to the database\n",
        "connection = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = connection.cursor()\n",
        "\n",
        "# Define the SQL query\n",
        "query = \"INSERT INTO your_table (id, name) VALUES (%s, %s)\"\n",
        "\n",
        "# Batch insert\n",
        "cursor.executemany(query, data)\n",
        "\n",
        "# Commit the changes\n",
        "connection.commit()\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "connection.close()\n",
        "import psycopg2\n",
        "\n",
        "# Assuming you have a list of data to be inserted\n",
        "data = [(1, 'John'), (2, 'Jane'), (3, 'Mark')]\n",
        "\n",
        "# Establish a connection to the database\n",
        "connection = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = connection.cursor()\n",
        "\n",
        "# Prepare the SQL statement\n",
        "query = \"INSERT INTO your_table (id, name) VALUES (%s, %s)\"\n",
        "cursor.prepare(query)\n",
        "\n",
        "# Execute the prepared statement multiple times\n",
        "for record in data:\n",
        "    cursor.execute(query, record)\n",
        "\n",
        "# Commit the changes\n",
        "connection.commit()\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "connection.close()\n",
        "import psycopg2\n",
        "\n",
        "# Assuming you have a CSV file with your data\n",
        "csv_file = '/path/to/your/file.csv'\n",
        "\n",
        "# Establish a connection to the database\n",
        "connection = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = connection.cursor()\n",
        "\n",
        "# Use the COPY command to load data from the CSV file\n",
        "query = f\"COPY your_table FROM '{csv_file}' DELIMITER ',' CSV HEADER\"\n",
        "cursor.execute(query)\n",
        "\n",
        "# Commit the changes\n",
        "connection.commit()\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "connection.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "KtWbtXYheTXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a)\n",
        "import psycopg2\n",
        "\n",
        "# Assuming you have a list of data to be inserted\n",
        "data = [(1, 'John'), (2, 'Jane'), (3, 'Mark')]\n",
        "\n",
        "# Batch size (number of records per batch)\n",
        "batch_size = 1000\n",
        "\n",
        "# Establish a connection to the database\n",
        "connection = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = connection.cursor()\n",
        "\n",
        "# Define the SQL query\n",
        "query = \"INSERT INTO your_table (id, name) VALUES (%s, %s)\"\n",
        "\n",
        "# Batch processing\n",
        "for i in range(0, len(data), batch_size):\n",
        "    batch_data = data[i:i + batch_size]  # Extract a batch of data\n",
        "\n",
        "    # Batch insert\n",
        "    cursor.executemany(query, batch_data)\n",
        "\n",
        "    # Commit the batch\n",
        "    connection.commit()\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "connection.close()\n"
      ],
      "metadata": {
        "id": "hMpwPEiKe4sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b)\n",
        "import psycopg2\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Assuming you have a list of data to be inserted\n",
        "data = [(1, 'John'), (2, 'Jane'), (3, 'Mark')]\n",
        "\n",
        "# Number of processes to spawn\n",
        "num_processes = 4\n",
        "\n",
        "# Establish a connection to the database\n",
        "connection = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
        "\n",
        "# Define the SQL query\n",
        "query = \"INSERT INTO your_table (id, name) VALUES (%s, %s)\"\n",
        "\n",
        "# Function to perform the batch insert\n",
        "def batch_insert(records):\n",
        "    # Create a cursor object for each process\n",
        "    cursor = connection.cursor()\n",
        "\n",
        "    # Batch insert\n",
        "    cursor.executemany(query, records)\n",
        "\n",
        "    # Commit the changes\n",
        "    connection.commit()\n",
        "\n",
        "    # Close the cursor\n",
        "    cursor.close()\n",
        "\n",
        "# Split the data into chunks for each process\n",
        "chunk_size = len(data) // num_processes\n",
        "chunks = [data[i:i + chunk_size] for i in range(0, len(data), chunk_size)]\n",
        "\n",
        "# Create a pool of processes\n",
        "pool = Pool(processes=num_processes)\n",
        "\n",
        "# Map the batch_insert function to the pool of processes\n",
        "pool.map(batch_insert, chunks)\n",
        "\n",
        "# Close the connection\n",
        "connection.close()\n"
      ],
      "metadata": {
        "id": "TSAseiFEfOlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c)\n",
        "import time\n",
        "import psycopg2\n",
        "\n",
        "# Assuming you have a list of data to be inserted\n",
        "data = [(1, 'John'), (2, 'Jane'), (3, 'Mark')]\n",
        "\n",
        "# Establish a connection to the database\n",
        "connection = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
        "\n",
        "# Create a cursor object\n",
        "cursor = connection.cursor()\n",
        "\n",
        "# Define the SQL query\n",
        "query = \"INSERT INTO your_table (id, name) VALUES (%s, %s)\"\n",
        "\n",
        "# Measure the execution time before data loading\n",
        "start_time = time.time()\n",
        "\n",
        "# Data loading process\n",
        "cursor.executemany(query, data)\n",
        "\n",
        "# Commit the changes\n",
        "connection.commit()\n",
        "\n",
        "# Measure the execution time after data loading\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Close the cursor and connection\n",
        "cursor.close()\n",
        "connection.close()\n",
        "\n",
        "# Print the elapsed time\n",
        "print(f\"Elapsed Time: {elapsed_time} seconds\")\n"
      ],
      "metadata": {
        "id": "TfReSDAXfdck"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}